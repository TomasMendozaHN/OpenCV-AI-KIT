{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satellite-piano",
   "metadata": {},
   "source": [
    "# Define model to convert (I used a different notebook to keep code clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eleven-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-integrity",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sporting-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Darknet('yolo_v3.cfg')\n",
    "net.load_weights('yolov3.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-timeline",
   "metadata": {},
   "source": [
    "# Set model into evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-delay",
   "metadata": {},
   "source": [
    "# Prepare input (for converting and verifying ONNX model output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "french-project",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks: \n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3, 128, 64, requires_grad=True)\n",
    "torch_out = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-revision",
   "metadata": {},
   "source": [
    "# Convert the model into ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aging-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks: \n"
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(net,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"YOLO_V3.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-renewal",
   "metadata": {},
   "source": [
    "# Load exported ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "northern-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"YOLO_V3.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-juice",
   "metadata": {},
   "source": [
    "# Verify ONNX output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "innocent-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"YOLO_V3.onnx\")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out[0]['x']), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-restoration",
   "metadata": {},
   "source": [
    "# Convert output back into dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-merit",
   "metadata": {},
   "source": [
    "#### The following function returns the ONNX output to the original Pytorch output.\n",
    "#### This is due to the original output being a dictionary, which is incompatible with the conversion to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "another-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ONNX_output_to_original(ort_outs):\n",
    "\n",
    "    results = {}\n",
    "    for idx in range(0,len(ort_outs),3):\n",
    "        counter = int(idx/3)\n",
    "        results[counter]={'x':ort_outs[idx], 'a':ort_outs[idx+1], 'n':ort_outs[idx+2]}\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interested-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ONNX_output_to_original(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-facial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
