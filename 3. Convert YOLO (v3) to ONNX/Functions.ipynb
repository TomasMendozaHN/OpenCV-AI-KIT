{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "valuable-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    blocks = []\n",
    "    fp = open(cfgfile)\n",
    "    block = None\n",
    "    line = fp.readline()\n",
    "    while line != '':\n",
    "        line = line.rstrip()\n",
    "        if line == '' or line[0] == '#':\n",
    "            line = fp.readline()\n",
    "            continue\n",
    "        elif line[0] == '[':\n",
    "            if block:\n",
    "                blocks.append(block)\n",
    "            block = dict()\n",
    "            block['type'] = line.lstrip('[').rstrip(']')\n",
    "            # set default value\n",
    "            if block['type'] == 'convolutional':\n",
    "                block['batch_normalize'] = 0\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            key = key.strip()\n",
    "            if key == 'type':\n",
    "                key = '_type'\n",
    "            value = value.strip()\n",
    "            block[key] = value\n",
    "        line = fp.readline()\n",
    "\n",
    "    if block:\n",
    "        blocks.append(block)\n",
    "    fp.close()\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def print_cfg(blocks):\n",
    "    print('layer     filters    size              input                output');\n",
    "    prev_width = 416\n",
    "    prev_height = 416\n",
    "    prev_filters = 3\n",
    "    out_filters = []\n",
    "    out_widths = []\n",
    "    out_heights = []\n",
    "    ind = -2\n",
    "    for block in blocks:\n",
    "        ind += 1\n",
    "        if block['type'] == 'net':\n",
    "            prev_width = int(block['width'])\n",
    "            prev_height = int(block['height'])\n",
    "            continue\n",
    "        elif block['type'] == 'convolutional':\n",
    "            filters = int(block['filters'])\n",
    "            kernel_size = int(block['size'])\n",
    "            stride = int(block['stride'])\n",
    "            is_pad = int(block['pad'])\n",
    "            pad = (kernel_size - 1) // 2 if is_pad else 0\n",
    "            width = (prev_width + 2 * pad - kernel_size) // stride + 1\n",
    "            height = (prev_height + 2 * pad - kernel_size) // stride + 1\n",
    "            print('%5d %-6s %4d  %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (\n",
    "            ind, 'conv', filters, kernel_size, kernel_size, stride, prev_width, prev_height, prev_filters, width,\n",
    "            height, filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'maxpool':\n",
    "            pool_size = int(block['size'])\n",
    "            stride = int(block['stride'])\n",
    "            width = prev_width // stride\n",
    "            height = prev_height // stride\n",
    "            print('%5d %-6s       %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (\n",
    "            ind, 'max', pool_size, pool_size, stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'avgpool':\n",
    "            width = 1\n",
    "            height = 1\n",
    "            print('%5d %-6s                   %3d x %3d x%4d   ->  %3d' % (\n",
    "            ind, 'avg', prev_width, prev_height, prev_filters, prev_filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'softmax':\n",
    "            print('%5d %-6s                                    ->  %3d' % (ind, 'softmax', prev_filters))\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'cost':\n",
    "            print('%5d %-6s                                     ->  %3d' % (ind, 'cost', prev_filters))\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'reorg':\n",
    "            stride = int(block['stride'])\n",
    "            filters = stride * stride * prev_filters\n",
    "            width = prev_width // stride\n",
    "            height = prev_height // stride\n",
    "            print('%5d %-6s             / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (\n",
    "            ind, 'reorg', stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'upsample':\n",
    "            stride = int(block['stride'])\n",
    "            filters = prev_filters\n",
    "            width = prev_width * stride\n",
    "            height = prev_height * stride\n",
    "            print('%5d %-6s           * %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (\n",
    "            ind, 'upsample', stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'route':\n",
    "            layers = block['layers'].split(',')\n",
    "            layers = [int(i) if int(i) > 0 else int(i) + ind for i in layers]\n",
    "            if len(layers) == 1:\n",
    "                print('%5d %-6s %d' % (ind, 'route', layers[0]))\n",
    "                prev_width = out_widths[layers[0]]\n",
    "                prev_height = out_heights[layers[0]]\n",
    "                prev_filters = out_filters[layers[0]]\n",
    "            elif len(layers) == 2:\n",
    "                print('%5d %-6s %d %d' % (ind, 'route', layers[0], layers[1]))\n",
    "                prev_width = out_widths[layers[0]]\n",
    "                prev_height = out_heights[layers[0]]\n",
    "                assert (prev_width == out_widths[layers[1]])\n",
    "                assert (prev_height == out_heights[layers[1]])\n",
    "                prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] in ['region', 'yolo']:\n",
    "            print('%5d %-6s' % (ind, 'detection'))\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'shortcut':\n",
    "            from_id = int(block['from'])\n",
    "            from_id = from_id if from_id > 0 else from_id + ind\n",
    "            print('%5d %-6s %d' % (ind, 'shortcut', from_id))\n",
    "            prev_width = out_widths[from_id]\n",
    "            prev_height = out_heights[from_id]\n",
    "            prev_filters = out_filters[from_id]\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'connected':\n",
    "            filters = int(block['output'])\n",
    "            print('%5d %-6s                            %d  ->  %3d' % (ind, 'connected', prev_filters, filters))\n",
    "            prev_filters = filters\n",
    "            out_widths.append(1)\n",
    "            out_heights.append(1)\n",
    "            out_filters.append(prev_filters)\n",
    "        else:\n",
    "            print('unknown type %s' % (block['type']))\n",
    "\n",
    "\n",
    "def load_conv(buf, start, conv_model):\n",
    "    num_w = conv_model.weight.numel()\n",
    "    num_b = conv_model.bias.numel()\n",
    "    # print(\"start: {}, num_w: {}, num_b: {}\".format(start, num_w, num_b))\n",
    "    # by ysyun, use .view_as()\n",
    "    conv_model.bias.data.copy_(torch.from_numpy(buf[start:start + num_b]).view_as(conv_model.bias.data));\n",
    "    start = start + num_b\n",
    "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start + num_w]).view_as(conv_model.weight.data));\n",
    "    start = start + num_w\n",
    "    return start\n",
    "\n",
    "\n",
    "def save_conv(fp, conv_model):\n",
    "    if conv_model.bias.is_cuda:\n",
    "        convert2cpu(conv_model.bias.data).numpy().tofile(fp)\n",
    "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
    "    else:\n",
    "        conv_model.bias.data.numpy().tofile(fp)\n",
    "        conv_model.weight.data.numpy().tofile(fp)\n",
    "\n",
    "\n",
    "def load_conv_bn(buf, start, conv_model, bn_model):\n",
    "    num_w = conv_model.weight.numel()\n",
    "    num_b = bn_model.bias.numel()\n",
    "    bn_model.bias.data.copy_(torch.from_numpy(buf[start:start + num_b]));\n",
    "    start = start + num_b\n",
    "    bn_model.weight.data.copy_(torch.from_numpy(buf[start:start + num_b]));\n",
    "    start = start + num_b\n",
    "    bn_model.running_mean.copy_(torch.from_numpy(buf[start:start + num_b]));\n",
    "    start = start + num_b\n",
    "    bn_model.running_var.copy_(torch.from_numpy(buf[start:start + num_b]));\n",
    "    start = start + num_b\n",
    "    # conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n",
    "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start + num_w]).view_as(conv_model.weight.data));\n",
    "    start = start + num_w\n",
    "    return start\n",
    "\n",
    "\n",
    "def save_conv_bn(fp, conv_model, bn_model):\n",
    "    if bn_model.bias.is_cuda:\n",
    "        convert2cpu(bn_model.bias.data).numpy().tofile(fp)\n",
    "        convert2cpu(bn_model.weight.data).numpy().tofile(fp)\n",
    "        convert2cpu(bn_model.running_mean).numpy().tofile(fp)\n",
    "        convert2cpu(bn_model.running_var).numpy().tofile(fp)\n",
    "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
    "    else:\n",
    "        bn_model.bias.data.numpy().tofile(fp)\n",
    "        bn_model.weight.data.numpy().tofile(fp)\n",
    "        bn_model.running_mean.numpy().tofile(fp)\n",
    "        bn_model.running_var.numpy().tofile(fp)\n",
    "        conv_model.weight.data.numpy().tofile(fp)\n",
    "\n",
    "\n",
    "def load_fc(buf, start, fc_model):\n",
    "    num_w = fc_model.weight.numel()\n",
    "    num_b = fc_model.bias.numel()\n",
    "    fc_model.bias.data.copy_(torch.from_numpy(buf[start:start + num_b]));\n",
    "    start = start + num_b\n",
    "    fc_model.weight.data.copy_(torch.from_numpy(buf[start:start + num_w]));\n",
    "    start = start + num_w\n",
    "    return start\n",
    "\n",
    "\n",
    "def save_fc(fp, fc_model):\n",
    "    fc_model.bias.data.numpy().tofile(fp)\n",
    "    fc_model.weight.data.numpy().tofile(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2cpu(gpu_matrix):\n",
    "    return torch.FloatTensor(gpu_matrix.size()).copy_(gpu_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionLayer(nn.Module):\n",
    "    def __init__(self, num_classes=0, anchors=[], num_anchors=1, use_cuda=None):\n",
    "        super(RegionLayer, self).__init__()\n",
    "        use_cuda = torch.cuda.is_available() and (True if use_cuda is None else use_cuda)\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "        self.anchor_step = len(anchors) // num_anchors\n",
    "        # self.anchors = torch.stack(torch.FloatTensor(anchors).split(self.anchor_step)).to(self.device)\n",
    "        self.anchors = torch.FloatTensor(anchors).view(self.num_anchors, self.anchor_step).to(self.device)\n",
    "        self.rescore = 1\n",
    "        self.coord_scale = 1\n",
    "        self.noobject_scale = 1\n",
    "        self.object_scale = 5\n",
    "        self.class_scale = 1\n",
    "        self.thresh = 0.6\n",
    "        self.seen = 0\n",
    "\n",
    "    def build_targets(self, pred_boxes, target, nH, nW):\n",
    "        nB = target.size(0)\n",
    "        nA = self.num_anchors\n",
    "        conf_mask = torch.ones(nB, nA, nH, nW) * self.noobject_scale\n",
    "        coord_mask = torch.zeros(nB, nA, nH, nW)\n",
    "        cls_mask = torch.zeros(nB, nA, nH, nW)\n",
    "        tcoord = torch.zeros(4, nB, nA, nH, nW)\n",
    "        tconf = torch.zeros(nB, nA, nH, nW)\n",
    "        tcls = torch.zeros(nB, nA, nH, nW)\n",
    "\n",
    "        nAnchors = nA * nH * nW\n",
    "        nPixels = nH * nW\n",
    "        nGT = 0  # number of ground truth\n",
    "        nRecall = 0\n",
    "        # it works faster on CPU than on GPU.\n",
    "        anchors = self.anchors.to(\"cpu\")\n",
    "\n",
    "        if self.seen < 12800:\n",
    "            tcoord[0].fill_(0.5)\n",
    "            tcoord[1].fill_(0.5)\n",
    "            coord_mask.fill_(1)\n",
    "\n",
    "        for b in range(nB):\n",
    "            cur_pred_boxes = pred_boxes[b * nAnchors:(b + 1) * nAnchors].t()\n",
    "            cur_ious = torch.zeros(nAnchors)\n",
    "            tbox = target[b].view(-1, 5).to(\"cpu\")\n",
    "            for t in range(50):\n",
    "                if tbox[t][1] == 0:\n",
    "                    break\n",
    "                gx, gw = [i * nW for i in (tbox[t][1], tbox[t][3])]\n",
    "                gy, gh = [i * nH for i in (tbox[t][2], tbox[t][4])]\n",
    "                cur_gt_boxes = torch.FloatTensor([gx, gy, gw, gh]).repeat(nAnchors, 1).t()\n",
    "                cur_ious = torch.max(cur_ious, multi_bbox_ious(cur_pred_boxes, cur_gt_boxes, x1y1x2y2=False))\n",
    "            ignore_ix = cur_ious > self.thresh\n",
    "            conf_mask[b][ignore_ix.view(nA, nH, nW)] = 0\n",
    "\n",
    "            for t in range(50):\n",
    "                if tbox[t][1] == 0:\n",
    "                    break\n",
    "                nGT += 1\n",
    "                gx, gw = [i * nW for i in (tbox[t][1], tbox[t][3])]\n",
    "                gy, gh = [i * nH for i in (tbox[t][2], tbox[t][4])]\n",
    "                gw, gh = gw.float(), gh.float()\n",
    "                gi, gj = int(gx), int(gy)\n",
    "\n",
    "                tmp_gt_boxes = torch.FloatTensor([0, 0, gw, gh]).repeat(nA, 1).t()\n",
    "                anchor_boxes = torch.cat((torch.zeros(nA, 2), anchors), 1).t()\n",
    "                tmp_ious = multi_bbox_ious(tmp_gt_boxes, anchor_boxes, x1y1x2y2=False)\n",
    "                best_iou, best_n = torch.max(tmp_ious, 0)\n",
    "\n",
    "                if self.anchor_step == 4:  # this part is not tested.\n",
    "                    tmp_ious_mask = (tmp_ious == best_iou)\n",
    "                    if tmp_ious_mask.sum() > 0:\n",
    "                        gt_pos = torch.FloatTensor([gi, gj, gx, gy]).repeat(nA, 1).t()\n",
    "                        an_pos = anchor_boxes[4:6]  # anchor_boxes are consisted of [0 0 aw ah ax ay]\n",
    "                        dist = pow(((gt_pos[0] + an_pos[0]) - gt_pos[2]), 2) + pow(\n",
    "                            ((gt_pos[1] + an_pos[1]) - gt_pos[3]), 2)\n",
    "                        dist[1 - tmp_ious_mask] = 10000  # set the large number for the small ious\n",
    "                        _, best_n = torch.min(dist, 0)\n",
    "\n",
    "                gt_box = torch.FloatTensor([gx, gy, gw, gh])\n",
    "                pred_box = pred_boxes[b * nAnchors + best_n * nPixels + gj * nW + gi]\n",
    "                iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False)\n",
    "\n",
    "                coord_mask[b][best_n][gj][gi] = 1\n",
    "                cls_mask[b][best_n][gj][gi] = 1\n",
    "                conf_mask[b][best_n][gj][gi] = self.object_scale\n",
    "                tcoord[0][b][best_n][gj][gi] = gx - gi\n",
    "                tcoord[1][b][best_n][gj][gi] = gy - gj\n",
    "                tcoord[2][b][best_n][gj][gi] = math.log(gw / anchors[best_n][0])\n",
    "                tcoord[3][b][best_n][gj][gi] = math.log(gh / anchors[best_n][1])\n",
    "                tcls[b][best_n][gj][gi] = tbox[t][0]\n",
    "                tconf[b][best_n][gj][gi] = iou if self.rescore else 1.\n",
    "                if iou > 0.5:\n",
    "                    nRecall += 1\n",
    "\n",
    "        return nGT, nRecall, coord_mask, conf_mask, cls_mask, tcoord, tconf, tcls\n",
    "\n",
    "    def get_mask_boxes(self, output):\n",
    "        if not isinstance(self.anchors, torch.Tensor):\n",
    "            self.anchors = torch.FloatTensor(self.anchors).view(self.num_anchors, self.anchor_step).to(self.device)\n",
    "        masked_anchors = self.anchors.view(-1)\n",
    "        num_anchors = torch.IntTensor([self.num_anchors]).to(self.device)\n",
    "        return {'x': output, 'a': masked_anchors, 'n': num_anchors}\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # output : BxAs*(4+1+num_classes)*H*W\n",
    "        t0 = time.time()\n",
    "        nB = output.data.size(0)  # batch size\n",
    "        nA = self.num_anchors\n",
    "        nC = self.num_classes\n",
    "        nH = output.data.size(2)\n",
    "        nW = output.data.size(3)\n",
    "        cls_anchor_dim = nB * nA * nH * nW\n",
    "\n",
    "        if not isinstance(self.anchors, torch.Tensor):\n",
    "            self.anchors = torch.FloatTensor(self.anchors).view(self.num_anchors, self.anchor_step).to(self.device)\n",
    "\n",
    "        output = output.view(nB, nA, (5 + nC), nH, nW)\n",
    "        cls_grid = torch.linspace(5, 5 + nC - 1, nC).long().to(self.device)\n",
    "        ix = torch.LongTensor(range(0, 5)).to(self.device)\n",
    "        pred_boxes = torch.FloatTensor(4, cls_anchor_dim).to(self.device)\n",
    "\n",
    "        coord = output.index_select(2, ix[0:4]).view(nB * nA, -1, nH * nW).transpose(0, 1).contiguous().view(-1,\n",
    "                                                                                                             cls_anchor_dim)  # x, y, w, h\n",
    "        coord[0:2] = coord[0:2].sigmoid()  # x, y\n",
    "        conf = output.index_select(2, ix[4]).view(nB, nA, nH, nW).sigmoid()\n",
    "        cls = output.index_select(2, cls_grid)\n",
    "        cls = cls.view(nB * nA, nC, nH * nW).transpose(1, 2).contiguous().view(cls_anchor_dim, nC)\n",
    "\n",
    "        t1 = time.time()\n",
    "        grid_x = torch.linspace(0, nW - 1, nW).repeat(nB * nA, nH, 1).view(cls_anchor_dim).to(self.device)\n",
    "        grid_y = torch.linspace(0, nH - 1, nH).repeat(nW, 1).t().repeat(nB * nA, 1, 1).view(cls_anchor_dim).to(\n",
    "            self.device)\n",
    "        anchor_w = self.anchors.index_select(1, ix[0]).repeat(1, nB * nH * nW).view(cls_anchor_dim)\n",
    "        anchor_h = self.anchors.index_select(1, ix[1]).repeat(1, nB * nH * nW).view(cls_anchor_dim)\n",
    "\n",
    "        pred_boxes[0] = coord[0] + grid_x\n",
    "        pred_boxes[1] = coord[1] + grid_y\n",
    "        pred_boxes[2] = coord[2].exp() * anchor_w\n",
    "        pred_boxes[3] = coord[3].exp() * anchor_h\n",
    "        # for build_targets. it works faster on CPU than on GPU\n",
    "        pred_boxes = convert2cpu(pred_boxes.transpose(0, 1).contiguous().view(-1, 4)).detach()\n",
    "\n",
    "        t2 = time.time()\n",
    "        nGT, nRecall, coord_mask, conf_mask, cls_mask, tcoord, tconf, tcls = \\\n",
    "            self.build_targets(pred_boxes, target.detach(), nH, nW)\n",
    "\n",
    "        cls_mask = (cls_mask == 1)\n",
    "        tcls = tcls[cls_mask].long().view(-1)\n",
    "        cls_mask = cls_mask.view(-1, 1).repeat(1, nC).to(self.device)\n",
    "        cls = cls[cls_mask].view(-1, nC)\n",
    "\n",
    "        nProposals = int((conf > 0.25).sum())\n",
    "\n",
    "        tcoord = tcoord.view(4, cls_anchor_dim).to(self.device)\n",
    "        tconf, tcls = tconf.to(self.device), tcls.to(self.device)\n",
    "        coord_mask, conf_mask = coord_mask.view(cls_anchor_dim).to(self.device), conf_mask.sqrt().to(self.device)\n",
    "\n",
    "        t3 = time.time()\n",
    "        loss_coord = self.coord_scale * nn.MSELoss(size_average=False)(coord * coord_mask, tcoord * coord_mask) / 2\n",
    "        # sqrt(object_scale)/2 is almost equal to 1.\n",
    "        loss_conf = nn.MSELoss(size_average=False)(conf * conf_mask, tconf * conf_mask) / 2\n",
    "        loss_cls = self.class_scale * nn.CrossEntropyLoss(size_average=False)(cls, tcls) if cls.size(0) > 0 else 0\n",
    "        loss = loss_coord + loss_conf + loss_cls\n",
    "        t4 = time.time()\n",
    "        if False:\n",
    "            print('-' * 30)\n",
    "            print('        activation : %f' % (t1 - t0))\n",
    "            print(' create pred_boxes : %f' % (t2 - t1))\n",
    "            print('     build targets : %f' % (t3 - t2))\n",
    "            print('       create loss : %f' % (t4 - t3))\n",
    "            print('             total : %f' % (t4 - t0))\n",
    "        print('%d: nGT %3d, nRC %3d, nPP %3d, loss: box %6.3f, conf %6.3f, class %6.3f, total %7.3f'\n",
    "              % (self.seen, nGT, nRecall, nProposals, loss_coord, loss_conf, loss_cls, loss))\n",
    "        if math.isnan(loss.item()):\n",
    "            print(conf, tconf)\n",
    "            sys.exit(0)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    if x1y1x2y2:\n",
    "        x1_min = min(box1[0], box2[0])\n",
    "        x2_max = max(box1[2], box2[2])\n",
    "        y1_min = min(box1[1], box2[1])\n",
    "        y2_max = max(box1[3], box2[3])\n",
    "        w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n",
    "        w2, h2 = box2[2] - box2[0], box2[3] - box2[1]\n",
    "    else:\n",
    "        w1, h1 = box1[2], box1[3]\n",
    "        w2, h2 = box2[2], box2[3]\n",
    "        x1_min = min(box1[0] - w1 / 2.0, box2[0] - w2 / 2.0)\n",
    "        x2_max = max(box1[0] + w1 / 2.0, box2[0] + w2 / 2.0)\n",
    "        y1_min = min(box1[1] - h1 / 2.0, box2[1] - h2 / 2.0)\n",
    "        y2_max = max(box1[1] + h1 / 2.0, box2[1] + h2 / 2.0)\n",
    "\n",
    "    w_union = x2_max - x1_min\n",
    "    h_union = y2_max - y1_min\n",
    "    w_cross = w1 + w2 - w_union\n",
    "    h_cross = h1 + h2 - h_union\n",
    "    carea = 0\n",
    "    if w_cross <= 0 or h_cross <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    carea = w_cross * h_cross\n",
    "    uarea = area1 + area2 - carea\n",
    "    return float(carea / uarea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_bbox_ious(boxes1, boxes2, x1y1x2y2=True):\n",
    "    if x1y1x2y2:\n",
    "        x1_min = torch.min(boxes1[0], boxes2[0])\n",
    "        x2_max = torch.max(boxes1[2], boxes2[2])\n",
    "        y1_min = torch.min(boxes1[1], boxes2[1])\n",
    "        y2_max = torch.max(boxes1[3], boxes2[3])\n",
    "        w1, h1 = boxes1[2] - boxes1[0], boxes1[3] - boxes1[1]\n",
    "        w2, h2 = boxes2[2] - boxes2[0], boxes2[3] - boxes2[1]\n",
    "    else:\n",
    "        w1, h1 = boxes1[2], boxes1[3]\n",
    "        w2, h2 = boxes2[2], boxes2[3]\n",
    "        x1_min = torch.min(boxes1[0] - w1 / 2.0, boxes2[0] - w2 / 2.0)\n",
    "        x2_max = torch.max(boxes1[0] + w1 / 2.0, boxes2[0] + w2 / 2.0)\n",
    "        y1_min = torch.min(boxes1[1] - h1 / 2.0, boxes2[1] - h2 / 2.0)\n",
    "        y2_max = torch.max(boxes1[1] + h1 / 2.0, boxes2[1] + h2 / 2.0)\n",
    "\n",
    "    w_union = x2_max - x1_min\n",
    "    h_union = y2_max - y1_min\n",
    "    w_cross = w1 + w2 - w_union\n",
    "    h_cross = h1 + h2 - h_union\n",
    "    mask = (((w_cross <= 0) + (h_cross <= 0)) > 0)\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    carea = w_cross * h_cross\n",
    "    carea[mask] = 0\n",
    "    uarea = area1 + area2 - carea\n",
    "    return carea / uarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLayer(nn.Module):\n",
    "    def __init__(self, anchor_mask=[], num_classes=0, anchors=[], num_anchors=1, use_cuda=None):\n",
    "        super(YoloLayer, self).__init__()\n",
    "        use_cuda = torch.cuda.is_available() and (True if use_cuda is None else use_cuda)\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = num_anchors\n",
    "        self.anchor_step = len(anchors) // num_anchors\n",
    "        self.rescore = 0\n",
    "        self.ignore_thresh = 0.5\n",
    "        self.truth_thresh = 1.\n",
    "        self.stride = 32\n",
    "        self.nth_layer = 0\n",
    "        self.seen = 0\n",
    "        self.net_width = 0\n",
    "        self.net_height = 0\n",
    "\n",
    "    def get_mask_boxes(self, output):\n",
    "        masked_anchors = []\n",
    "        for m in self.anchor_mask:\n",
    "            masked_anchors += self.anchors[m * self.anchor_step:(m + 1) * self.anchor_step]\n",
    "        masked_anchors = [anchor / self.stride for anchor in masked_anchors]\n",
    "\n",
    "        masked_anchors = torch.FloatTensor(masked_anchors).to(self.device)\n",
    "        num_anchors = torch.IntTensor([len(self.anchor_mask)]).to(self.device)\n",
    "        return {'x': output, 'a': masked_anchors, 'n': num_anchors}\n",
    "\n",
    "    def build_targets(self, pred_boxes, target, anchors, nA, nH, nW):\n",
    "        nB = target.size(0)\n",
    "        anchor_step = anchors.size(1)  # anchors[nA][anchor_step]\n",
    "        conf_mask = torch.ones(nB, nA, nH, nW)\n",
    "        coord_mask = torch.zeros(nB, nA, nH, nW)\n",
    "        cls_mask = torch.zeros(nB, nA, nH, nW)\n",
    "        tcoord = torch.zeros(4, nB, nA, nH, nW)\n",
    "        tconf = torch.zeros(nB, nA, nH, nW)\n",
    "        tcls = torch.zeros(nB, nA, nH, nW)\n",
    "        twidth, theight = self.net_width / self.stride, self.net_height / self.stride\n",
    "\n",
    "        nAnchors = nA * nH * nW\n",
    "        nPixels = nH * nW\n",
    "        nGT = 0\n",
    "        nRecall = 0\n",
    "        nRecall75 = 0\n",
    "\n",
    "        # it works faster on CPU than on GPU.\n",
    "        anchors = anchors.to(\"cpu\")\n",
    "\n",
    "        for b in range(nB):\n",
    "            cur_pred_boxes = pred_boxes[b * nAnchors:(b + 1) * nAnchors].t()\n",
    "            cur_ious = torch.zeros(nAnchors)\n",
    "            tbox = target[b].view(-1, 5).to(\"cpu\")\n",
    "            for t in range(50):\n",
    "                if tbox[t][1] == 0:\n",
    "                    break\n",
    "                gx, gy = tbox[t][1] * nW, tbox[t][2] * nH\n",
    "                gw, gh = tbox[t][3] * twidth, tbox[t][4] * theight\n",
    "                cur_gt_boxes = torch.FloatTensor([gx, gy, gw, gh]).repeat(nAnchors, 1).t()\n",
    "                cur_ious = torch.max(cur_ious, multi_bbox_ious(cur_pred_boxes, cur_gt_boxes, x1y1x2y2=False))\n",
    "            ignore_ix = cur_ious > self.ignore_thresh\n",
    "            conf_mask[b][ignore_ix.view(nA, nH, nW)] = 0\n",
    "\n",
    "            for t in range(50):\n",
    "                if tbox[t][1] == 0:\n",
    "                    break\n",
    "                nGT += 1\n",
    "                gx, gy = tbox[t][1] * nW, tbox[t][2] * nH\n",
    "                gw, gh = tbox[t][3] * twidth, tbox[t][4] * theight\n",
    "                gw, gh = gw.float(), gh.float()\n",
    "                gi, gj = int(gx), int(gy)\n",
    "\n",
    "                tmp_gt_boxes = torch.FloatTensor([0, 0, gw, gh]).repeat(nA, 1).t()\n",
    "                anchor_boxes = torch.cat((torch.zeros(nA, anchor_step), anchors), 1).t()\n",
    "                _, best_n = torch.max(multi_bbox_ious(tmp_gt_boxes, anchor_boxes, x1y1x2y2=False), 0)\n",
    "\n",
    "                gt_box = torch.FloatTensor([gx, gy, gw, gh])\n",
    "                pred_box = pred_boxes[b * nAnchors + best_n * nPixels + gj * nW + gi]\n",
    "                iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False)\n",
    "\n",
    "                coord_mask[b][best_n][gj][gi] = 1\n",
    "                cls_mask[b][best_n][gj][gi] = 1\n",
    "                conf_mask[b][best_n][gj][gi] = 1\n",
    "                tcoord[0][b][best_n][gj][gi] = gx - gi\n",
    "                tcoord[1][b][best_n][gj][gi] = gy - gj\n",
    "                tcoord[2][b][best_n][gj][gi] = math.log(gw / anchors[best_n][0])\n",
    "                tcoord[3][b][best_n][gj][gi] = math.log(gh / anchors[best_n][1])\n",
    "                tcls[b][best_n][gj][gi] = tbox[t][0]\n",
    "                tconf[b][best_n][gj][gi] = iou if self.rescore else 1.\n",
    "\n",
    "                if iou > 0.5:\n",
    "                    nRecall += 1\n",
    "                    if iou > 0.75:\n",
    "                        nRecall75 += 1\n",
    "\n",
    "        return nGT, nRecall, nRecall75, coord_mask, conf_mask, cls_mask, tcoord, tconf, tcls\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # output : BxAs*(4+1+num_classes)*H*W\n",
    "        mask_tuple = self.get_mask_boxes(output)\n",
    "        t0 = time.time()\n",
    "        nB = output.data.size(0)  # batch size\n",
    "        nA = mask_tuple['n'].item()  # num_anchors\n",
    "        nC = self.num_classes\n",
    "        nH = output.data.size(2)\n",
    "        nW = output.data.size(3)\n",
    "        anchor_step = mask_tuple['a'].size(0) // nA\n",
    "        anchors = mask_tuple['a'].view(nA, anchor_step).to(self.device)\n",
    "        cls_anchor_dim = nB * nA * nH * nW\n",
    "\n",
    "        output = output.view(nB, nA, (5 + nC), nH, nW)\n",
    "        cls_grid = torch.linspace(5, 5 + nC - 1, nC).long().to(self.device)\n",
    "        ix = torch.LongTensor(range(0, 5)).to(self.device)\n",
    "        pred_boxes = torch.FloatTensor(4, cls_anchor_dim).to(self.device)\n",
    "\n",
    "        coord = output.index_select(2, ix[0:4]).view(nB * nA, -1, nH * nW).transpose(0, 1).contiguous().view(-1,\n",
    "                                                                                                             cls_anchor_dim)  # x, y, w, h\n",
    "        coord[0:2] = coord[0:2].sigmoid()  # x, y\n",
    "        conf = output.index_select(2, ix[4]).view(nB, nA, nH, nW).sigmoid()\n",
    "        cls = output.index_select(2, cls_grid)\n",
    "        cls = cls.view(nB * nA, nC, nH * nW).transpose(1, 2).contiguous().view(cls_anchor_dim, nC)\n",
    "\n",
    "        t1 = time.time()\n",
    "        grid_x = torch.linspace(0, nW - 1, nW).repeat(nB * nA, nH, 1).view(cls_anchor_dim).to(self.device)\n",
    "        grid_y = torch.linspace(0, nH - 1, nH).repeat(nW, 1).t().repeat(nB * nA, 1, 1).view(cls_anchor_dim).to(\n",
    "            self.device)\n",
    "        anchor_w = anchors.index_select(1, ix[0]).repeat(1, nB * nH * nW).view(cls_anchor_dim)\n",
    "        anchor_h = anchors.index_select(1, ix[1]).repeat(1, nB * nH * nW).view(cls_anchor_dim)\n",
    "\n",
    "        pred_boxes[0] = coord[0] + grid_x\n",
    "        pred_boxes[1] = coord[1] + grid_y\n",
    "        pred_boxes[2] = coord[2].exp() * anchor_w\n",
    "        pred_boxes[3] = coord[3].exp() * anchor_h\n",
    "        # for build_targets. it works faster on CPU than on GPU\n",
    "        pred_boxes = convert2cpu(pred_boxes.transpose(0, 1).contiguous().view(-1, 4)).detach()\n",
    "\n",
    "        t2 = time.time()\n",
    "        nGT, nRecall, nRecall75, coord_mask, conf_mask, cls_mask, tcoord, tconf, tcls = \\\n",
    "            self.build_targets(pred_boxes, target.detach(), anchors.detach(), nA, nH, nW)\n",
    "\n",
    "        cls_mask = (cls_mask == 1)\n",
    "        tcls = tcls[cls_mask].long().view(-1)\n",
    "        cls_mask = cls_mask.view(-1, 1).repeat(1, nC).to(self.device)\n",
    "        cls = cls[cls_mask].view(-1, nC)\n",
    "\n",
    "        nProposals = int((conf > 0.25).sum())\n",
    "\n",
    "        tcoord = tcoord.view(4, cls_anchor_dim).to(self.device)\n",
    "        tconf, tcls = tconf.to(self.device), tcls.to(self.device)\n",
    "        coord_mask, conf_mask = coord_mask.view(cls_anchor_dim).to(self.device), conf_mask.to(self.device)\n",
    "\n",
    "        t3 = time.time()\n",
    "        loss_coord = nn.MSELoss(size_average=False)(coord * coord_mask, tcoord * coord_mask) / 2\n",
    "        loss_conf = nn.MSELoss(size_average=False)(conf * conf_mask, tconf * conf_mask)\n",
    "        loss_cls = nn.CrossEntropyLoss(size_average=False)(cls, tcls) if cls.size(0) > 0 else 0\n",
    "        loss = loss_coord + loss_conf + loss_cls\n",
    "\n",
    "        t4 = time.time()\n",
    "        if False:\n",
    "            print('-' * 30)\n",
    "            print('        activation : %f' % (t1 - t0))\n",
    "            print(' create pred_boxes : %f' % (t2 - t1))\n",
    "            print('     build targets : %f' % (t3 - t2))\n",
    "            print('       create loss : %f' % (t4 - t3))\n",
    "            print('             total : %f' % (t4 - t0))\n",
    "        print(\n",
    "            '%d: Layer(%03d) nGT %3d, nRC %3d, nRC75 %3d, nPP %3d, loss: box %6.3f, conf %6.3f, class %6.3f, total %7.3f'\n",
    "            % (self.seen, self.nth_layer, nGT, nRecall, nRecall75, nProposals, loss_coord, loss_conf, loss_cls, loss))\n",
    "        if math.isnan(loss.item()):\n",
    "            print(conf, tconf)\n",
    "            sys.exit(0)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolStride1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPoolStride1, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.pad(x, (0,1,0,1), mode='replicate'), 2, stride=1)\n",
    "        return x\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, stride=2):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        stride = self.stride\n",
    "        assert(x.data.dim() == 4)\n",
    "        B = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        ws = stride\n",
    "        hs = stride\n",
    "        x = x.view(B, C, H, 1, W, 1).expand(B, C, H, hs, W, ws).contiguous().view(B, C, H*hs, W*ws)\n",
    "        return x\n",
    "\n",
    "class Reorg(nn.Module):\n",
    "    def __init__(self, stride=2):\n",
    "        super(Reorg, self).__init__()\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        stride = self.stride\n",
    "        assert(x.data.dim() == 4)\n",
    "        B = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        assert(H % stride == 0)\n",
    "        assert(W % stride == 0)\n",
    "        ws = stride\n",
    "        hs = stride\n",
    "        x = x.view(B, C, H//hs, hs, W//ws, ws).transpose(3,4).contiguous()\n",
    "        x = x.view(B, C, (H//hs)*(W//ws), hs*ws).transpose(2,3).contiguous()\n",
    "        x = x.view(B, C, hs*ws, H//hs, W//ws).transpose(1,2).contiguous()\n",
    "        x = x.view(B, hs*ws*C, H//hs, W//ws)\n",
    "        return x\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        x = F.avg_pool2d(x, (H, W))\n",
    "        x = x.view(N, C)\n",
    "        return x\n",
    "\n",
    "# for route and shortcut\n",
    "class EmptyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyModule, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# support route shortcut and reorg\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    def getLossLayers(self):\n",
    "        loss_layers = []\n",
    "        for m in self.models:\n",
    "            if isinstance(m, RegionLayer) or isinstance(m, YoloLayer):\n",
    "                loss_layers.append(m)\n",
    "        return loss_layers\n",
    "\n",
    "    def __init__(self, cfgfile, use_cuda=True):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.blocks = parse_cfg(cfgfile)\n",
    "        self.models = self.create_network(self.blocks) # merge conv, bn,leaky\n",
    "        self.loss_layers = self.getLossLayers()\n",
    "\n",
    "        #self.width = int(self.blocks[0]['width'])\n",
    "        #self.height = int(self.blocks[0]['height'])\n",
    "\n",
    "        if len(self.loss_layers) > 0:\n",
    "            last = len(self.loss_layers)-1\n",
    "            self.anchors = self.loss_layers[last].anchors\n",
    "            self.num_anchors = self.loss_layers[last].num_anchors\n",
    "            self.anchor_step = self.loss_layers[last].anchor_step\n",
    "            self.num_classes = self.loss_layers[last].num_classes\n",
    "\n",
    "        # default format : major=0, minor=1\n",
    "        self.header = torch.IntTensor([0,1,0,0])\n",
    "        self.seen = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        ind = -2\n",
    "        self.loss_layers = None\n",
    "        outputs = dict()\n",
    "        out_boxes = dict()\n",
    "        outno = 0\n",
    "        for block in self.blocks:\n",
    "            ind = ind + 1\n",
    "\n",
    "            if block['type'] == 'net':\n",
    "                continue\n",
    "            elif block['type'] in ['convolutional', 'maxpool', 'reorg', 'upsample', 'avgpool', 'softmax', 'connected']:\n",
    "                x = self.models[ind](x)\n",
    "                outputs[ind] = x\n",
    "            elif block['type'] == 'route':\n",
    "                layers = block['layers'].split(',')\n",
    "                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
    "                if len(layers) == 1:\n",
    "                    x = outputs[layers[0]]\n",
    "                elif len(layers) == 2:\n",
    "                    x1 = outputs[layers[0]]\n",
    "                    x2 = outputs[layers[1]]\n",
    "                    x = torch.cat((x1,x2),1)\n",
    "                outputs[ind] = x\n",
    "            elif block['type'] == 'shortcut':\n",
    "                from_layer = int(block['from'])\n",
    "                activation = block['activation']\n",
    "                from_layer = from_layer if from_layer > 0 else from_layer + ind\n",
    "                x1 = outputs[from_layer]\n",
    "                x2 = outputs[ind-1]\n",
    "                x  = x1 + x2\n",
    "                if activation == 'leaky':\n",
    "                    x = F.leaky_relu(x, 0.1, inplace=True)\n",
    "                elif activation == 'relu':\n",
    "                    x = F.relu(x, inplace=True)\n",
    "                outputs[ind] = x\n",
    "            elif block['type'] in [ 'region', 'yolo']:\n",
    "                boxes = self.models[ind].get_mask_boxes(x)\n",
    "                out_boxes[outno]= boxes\n",
    "                outno += 1\n",
    "                outputs[ind] = None\n",
    "            elif block['type'] == 'cost':\n",
    "                continue\n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "                \n",
    "        print('blocks: ')        \n",
    "        if outno != 0:\n",
    "            result=[]\n",
    "            for idx in out_boxes.keys():\n",
    "                result.append(out_boxes[idx])               \n",
    "#                 result.append([out_boxes[idx]['x'], out_boxes[idx]['a'], out_boxes[idx]['n']])  \n",
    "        return x if outno == 0 else result\n",
    "\n",
    "    def print_network(self):\n",
    "        print_cfg(self.blocks)\n",
    "\n",
    "    def create_network(self, blocks):\n",
    "        models = nn.ModuleList()\n",
    "    \n",
    "        prev_filters = 3\n",
    "        out_filters =[]\n",
    "        prev_stride = 1\n",
    "        out_strides = []\n",
    "        conv_id = 0\n",
    "        ind = -2\n",
    "        for block in blocks:\n",
    "            ind += 1\n",
    "            if block['type'] == 'net':\n",
    "                prev_filters = int(block['channels'])\n",
    "                self.width = int(block['width'])\n",
    "                self.height = int(block['height'])\n",
    "                continue\n",
    "            elif block['type'] == 'convolutional':\n",
    "                conv_id = conv_id + 1\n",
    "                batch_normalize = int(block['batch_normalize'])\n",
    "                filters = int(block['filters'])\n",
    "                kernel_size = int(block['size'])\n",
    "                stride = int(block['stride'])\n",
    "                is_pad = int(block['pad'])\n",
    "                pad = (kernel_size-1)//2 if is_pad else 0\n",
    "                activation = block['activation']\n",
    "                model = nn.Sequential()\n",
    "                if batch_normalize:\n",
    "                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=False))\n",
    "                    model.add_module('bn{0}'.format(conv_id), nn.BatchNorm2d(filters))\n",
    "                    #model.add_module('bn{0}'.format(conv_id), BN2d(filters))\n",
    "                else:\n",
    "                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad))\n",
    "                if activation == 'leaky':\n",
    "                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\n",
    "                elif activation == 'relu':\n",
    "                    model.add_module('relu{0}'.format(conv_id), nn.ReLU(inplace=True))\n",
    "                prev_filters = filters\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = stride * prev_stride\n",
    "                out_strides.append(prev_stride)                \n",
    "                models.append(model)\n",
    "            elif block['type'] == 'maxpool':\n",
    "                pool_size = int(block['size'])\n",
    "                stride = int(block['stride'])\n",
    "                if stride > 1:\n",
    "                    model = nn.MaxPool2d(pool_size, stride)\n",
    "                else:\n",
    "                    model = MaxPoolStride1()\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = stride * prev_stride\n",
    "                out_strides.append(prev_stride)                \n",
    "                models.append(model)\n",
    "            elif block['type'] == 'avgpool':\n",
    "                model = GlobalAvgPool2d()\n",
    "                out_filters.append(prev_filters)\n",
    "                models.append(model)\n",
    "            elif block['type'] == 'softmax':\n",
    "                model = nn.Softmax()\n",
    "                out_strides.append(prev_stride)\n",
    "                out_filters.append(prev_filters)\n",
    "                models.append(model)\n",
    "            elif block['type'] == 'cost':\n",
    "                if block['_type'] == 'sse':\n",
    "                    model = nn.MSELoss(size_average=True)\n",
    "                elif block['_type'] == 'L1':\n",
    "                    model = nn.L1Loss(size_average=True)\n",
    "                elif block['_type'] == 'smooth':\n",
    "                    model = nn.SmoothL1Loss(size_average=True)\n",
    "                out_filters.append(1)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(model)\n",
    "            elif block['type'] == 'reorg':\n",
    "                stride = int(block['stride'])\n",
    "                prev_filters = stride * stride * prev_filters\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = prev_stride * stride\n",
    "                out_strides.append(prev_stride)                \n",
    "                models.append(Reorg(stride))\n",
    "            elif block['type'] == 'upsample':\n",
    "                stride = int(block['stride'])\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = prev_stride / stride\n",
    "                out_strides.append(prev_stride)                \n",
    "                #models.append(nn.Upsample(scale_factor=stride, mode='nearest'))\n",
    "                models.append(Upsample(stride))\n",
    "            elif block['type'] == 'route':\n",
    "                layers = block['layers'].split(',')\n",
    "                ind = len(models)\n",
    "                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
    "                if len(layers) == 1:\n",
    "                    prev_filters = out_filters[layers[0]]\n",
    "                    prev_stride = out_strides[layers[0]]\n",
    "                elif len(layers) == 2:\n",
    "                    assert(layers[0] == ind - 1)\n",
    "                    prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
    "                    prev_stride = out_strides[layers[0]]\n",
    "                out_filters.append(prev_filters)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(EmptyModule())\n",
    "            elif block['type'] == 'shortcut':\n",
    "                ind = len(models)\n",
    "                prev_filters = out_filters[ind-1]\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = out_strides[ind-1]\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(EmptyModule())\n",
    "            elif block['type'] == 'connected':\n",
    "                filters = int(block['output'])\n",
    "                if block['activation'] == 'linear':\n",
    "                    model = nn.Linear(prev_filters, filters)\n",
    "                elif block['activation'] == 'leaky':\n",
    "                    model = nn.Sequential(\n",
    "                               nn.Linear(prev_filters, filters),\n",
    "                               nn.LeakyReLU(0.1, inplace=True))\n",
    "                elif block['activation'] == 'relu':\n",
    "                    model = nn.Sequential(\n",
    "                               nn.Linear(prev_filters, filters),\n",
    "                               nn.ReLU(inplace=True))\n",
    "                prev_filters = filters\n",
    "                out_filters.append(prev_filters)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(model)\n",
    "            elif block['type'] == 'region':\n",
    "                region_layer = RegionLayer(use_cuda=self.use_cuda)\n",
    "                anchors = block['anchors'].split(',')\n",
    "                region_layer.anchors = [float(i) for i in anchors]\n",
    "                region_layer.num_classes = int(block['classes'])\n",
    "                region_layer.num_anchors = int(block['num'])\n",
    "                region_layer.anchor_step = len(region_layer.anchors)//region_layer.num_anchors\n",
    "                region_layer.rescore = int(block['rescore'])\n",
    "                region_layer.object_scale = float(block['object_scale'])\n",
    "                region_layer.noobject_scale = float(block['noobject_scale'])\n",
    "                region_layer.class_scale = float(block['class_scale'])\n",
    "                region_layer.coord_scale = float(block['coord_scale'])\n",
    "                region_layer.thresh = float(block['thresh'])\n",
    "                out_filters.append(prev_filters)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(region_layer)\n",
    "            elif block['type'] == 'yolo':\n",
    "                yolo_layer = YoloLayer(use_cuda=self.use_cuda)\n",
    "                anchors = block['anchors'].split(',')\n",
    "                anchor_mask = block['mask'].split(',')\n",
    "                yolo_layer.anchor_mask = [int(i) for i in anchor_mask]\n",
    "                yolo_layer.anchors = [float(i) for i in anchors]\n",
    "                yolo_layer.num_classes = int(block['classes'])\n",
    "                yolo_layer.num_anchors = int(block['num'])\n",
    "                yolo_layer.anchor_step = len(yolo_layer.anchors)//yolo_layer.num_anchors\n",
    "                try:\n",
    "                    yolo_layer.rescore = int(block['rescore'])\n",
    "                except:\n",
    "                    pass\n",
    "                yolo_layer.ignore_thresh = float(block['ignore_thresh'])\n",
    "                yolo_layer.truth_thresh = float(block['truth_thresh'])\n",
    "                yolo_layer.stride = prev_stride\n",
    "                yolo_layer.nth_layer = ind\n",
    "                yolo_layer.net_width = self.width\n",
    "                yolo_layer.net_height = self.height\n",
    "                out_filters.append(prev_filters)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(yolo_layer)                \n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "    \n",
    "        return models\n",
    "\n",
    "    def load_binfile(self, weightfile):\n",
    "        fp = open(weightfile, 'rb')\n",
    "       \n",
    "        version = np.fromfile(fp, count=3, dtype=np.int32)\n",
    "        version = [int(i) for i in version]\n",
    "        if version[0]*10+version[1] >=2 and version[0] < 1000 and version[1] < 1000:\n",
    "            seen = np.fromfile(fp, count=1, dtype=np.int64)\n",
    "        else:\n",
    "            seen = np.fromfile(fp, count=1, dtype=np.int32)\n",
    "        self.header = torch.from_numpy(np.concatenate((version, seen), axis=0))\n",
    "        self.seen = int(seen)\n",
    "        body = np.fromfile(fp, dtype=np.float32)\n",
    "        fp.close()\n",
    "        return body\n",
    "\n",
    "    def load_weights(self, weightfile):\n",
    "        buf = self.load_binfile(weightfile)\n",
    "\n",
    "        start = 0\n",
    "        ind = -2\n",
    "        for block in self.blocks:\n",
    "            if start >= buf.size:\n",
    "                break\n",
    "            ind = ind + 1\n",
    "            if block['type'] == 'net':\n",
    "                continue\n",
    "            elif block['type'] == 'convolutional':\n",
    "                model = self.models[ind]\n",
    "                batch_normalize = int(block['batch_normalize'])\n",
    "                if batch_normalize:\n",
    "                    start = load_conv_bn(buf, start, model[0], model[1])\n",
    "                else:\n",
    "                    start = load_conv(buf, start, model[0])\n",
    "            elif block['type'] == 'connected':\n",
    "                model = self.models[ind]\n",
    "                if block['activation'] != 'linear':\n",
    "                    start = load_fc(buf, start, model[0])\n",
    "                else:\n",
    "                    start = load_fc(buf, start, model)\n",
    "            elif block['type'] == 'maxpool':\n",
    "                pass\n",
    "            elif block['type'] == 'reorg':\n",
    "                pass\n",
    "            elif block['type'] == 'upsample':\n",
    "                pass\n",
    "            elif block['type'] == 'route':\n",
    "                pass\n",
    "            elif block['type'] == 'shortcut':\n",
    "                pass\n",
    "            elif block['type'] == 'region':\n",
    "                pass\n",
    "            elif block['type'] == 'yolo':\n",
    "                pass                \n",
    "            elif block['type'] == 'avgpool':\n",
    "                pass\n",
    "            elif block['type'] == 'softmax':\n",
    "                pass\n",
    "            elif block['type'] == 'cost':\n",
    "                pass\n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "\n",
    "    def save_weights(self, outfile, cutoff=0):\n",
    "        if cutoff <= 0:\n",
    "            cutoff = len(self.blocks)-1\n",
    "\n",
    "        fp = open(outfile, 'wb')\n",
    "        self.header[3] = self.seen\n",
    "        header = np.array(self.header[0:3].numpy(), np.int32)\n",
    "        header.tofile(fp)\n",
    "        if (self.header[0]*10+self.header[1]) >= 2:\n",
    "            seen = np.array(self.seen, np.int64)\n",
    "        else:\n",
    "            seen = np.array(self.seen, np.int32)\n",
    "        seen.tofile(fp)\n",
    "\n",
    "        ind = -1\n",
    "        for blockId in range(1, cutoff+1):\n",
    "            ind = ind + 1\n",
    "            block = self.blocks[blockId]\n",
    "            if block['type'] == 'convolutional':\n",
    "                model = self.models[ind]\n",
    "                batch_normalize = int(block['batch_normalize'])\n",
    "                if batch_normalize:\n",
    "                    save_conv_bn(fp, model[0], model[1])\n",
    "                else:\n",
    "                    save_conv(fp, model[0])\n",
    "            elif block['type'] == 'connected':\n",
    "                model = self.models[ind]\n",
    "                if block['activation'] != 'linear':\n",
    "                    save_fc(fc, model)\n",
    "                else:\n",
    "                    save_fc(fc, model[0])\n",
    "            elif block['type'] == 'maxpool':\n",
    "                pass\n",
    "            elif block['type'] == 'reorg':\n",
    "                pass\n",
    "            elif block['type'] == 'upsample':\n",
    "                pass                \n",
    "            elif block['type'] == 'route':\n",
    "                pass\n",
    "            elif block['type'] == 'shortcut':\n",
    "                pass\n",
    "            elif block['type'] == 'region':\n",
    "                pass\n",
    "            elif block['type'] == 'yolo':\n",
    "                pass\n",
    "            elif block['type'] == 'avgpool':\n",
    "                pass\n",
    "            elif block['type'] == 'softmax':\n",
    "                pass\n",
    "            elif block['type'] == 'cost':\n",
    "                pass\n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "        fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv3(object):\n",
    "    def __init__(self, cfgfile, weightfile, namesfile, score_thresh=0.7, conf_thresh=0.01, nms_thresh=0.45,\n",
    "                 is_xywh=False, use_cuda=True):\n",
    "        # net definition\n",
    "        self.net = Darknet(cfgfile)\n",
    "        self.net.load_weights(weightfile)\n",
    "        logger = logging.getLogger(\"root.detector\")\n",
    "        logger.info('Loading weights from %s... Done!' % (weightfile))\n",
    "        self.device = \"cuda\" if use_cuda else \"cpu\"\n",
    "        self.net.eval()\n",
    "        self.net.to(self.device)\n",
    "\n",
    "        # constants\n",
    "        self.size = self.net.width, self.net.height\n",
    "        self.score_thresh = score_thresh\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.use_cuda = use_cuda\n",
    "        self.is_xywh = is_xywh\n",
    "        self.num_classes = self.net.num_classes\n",
    "        self.class_names = self.load_class_names(namesfile)\n",
    "\n",
    "    def __call__(self, ori_img):\n",
    "        # img to tensor\n",
    "        assert isinstance(ori_img, np.ndarray), \"input must be a numpy array!\"\n",
    "        img = ori_img.astype(np.float) / 255.\n",
    "\n",
    "        img = cv2.resize(img, self.size)\n",
    "        img = torch.from_numpy(img).float().permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "        # forward\n",
    "        with torch.no_grad():\n",
    "            img = img.to(self.device)\n",
    "            out_boxes = self.net(img)\n",
    "            boxes = get_all_boxes(out_boxes, self.conf_thresh, self.num_classes,\n",
    "                                  use_cuda=self.use_cuda)  # batch size is 1\n",
    "            # boxes = nms(boxes, self.nms_thresh)\n",
    "\n",
    "            boxes = post_process(boxes, self.net.num_classes, self.conf_thresh, self.nms_thresh)[0].cpu()\n",
    "            boxes = boxes[boxes[:, -2] > self.score_thresh, :]  # bbox xmin ymin xmax ymax\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            bbox = torch.FloatTensor([]).reshape([0, 4])\n",
    "            cls_conf = torch.FloatTensor([])\n",
    "            cls_ids = torch.LongTensor([])\n",
    "        else:\n",
    "            height, width = ori_img.shape[:2]\n",
    "            bbox = boxes[:, :4]\n",
    "            if self.is_xywh:\n",
    "                # bbox x y w h\n",
    "                bbox = xyxy_to_xywh(bbox)\n",
    "\n",
    "            bbox *= torch.FloatTensor([[width, height, width, height]])\n",
    "            cls_conf = boxes[:, 5]\n",
    "            cls_ids = boxes[:, 6].long()\n",
    "        return bbox.numpy(), cls_conf.numpy(), cls_ids.numpy()\n",
    "\n",
    "    def load_class_names(self, namesfile):\n",
    "        with open(namesfile, 'r', encoding='utf8') as fp:\n",
    "            class_names = [line.strip() for line in fp.readlines()]\n",
    "        return class_names\n",
    "\n",
    "\n",
    "def demo():\n",
    "    import os\n",
    "    from vizer.draw import draw_boxes\n",
    "\n",
    "    yolo = YOLOv3(\"cfg/yolo_v3.cfg\", \"weight/yolov3.weights\", \"cfg/coco.names\")\n",
    "    print(\"yolo.size =\", yolo.size)\n",
    "    root = \"./demo\"\n",
    "    resdir = os.path.join(root, \"results\")\n",
    "    os.makedirs(resdir, exist_ok=True)\n",
    "    files = [os.path.join(root, file) for file in os.listdir(root) if file.endswith('.jpg')]\n",
    "    files.sort()\n",
    "    for filename in files:\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        bbox, cls_conf, cls_ids = yolo(img)\n",
    "\n",
    "        if bbox is not None:\n",
    "            img = draw_boxes(img, bbox, cls_ids, cls_conf, class_name_map=yolo.class_names)\n",
    "        # save results\n",
    "        cv2.imwrite(os.path.join(resdir, os.path.basename(filename)), img[:, :, (2, 1, 0)])\n",
    "        # imshow\n",
    "        # cv2.namedWindow(\"yolo\", cv2.WINDOW_NORMAL)\n",
    "        # cv2.resizeWindow(\"yolo\", 600,600)\n",
    "        # cv2.imshow(\"yolo\",res[:,:,(2,1,0)])\n",
    "        # cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
